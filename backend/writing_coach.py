"""
AI å†™ä½œç§æ•™æ¨¡å— - æä¾›é›…æ€å†™ä½œè¯„åˆ†å’Œè¯é¢˜è®­ç»ƒåŠŸèƒ½
"""
import os
import json
from typing import List, Optional, Dict, Any

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy import create_engine, Column, Integer, String, Text, JSON as SA_JSON, DateTime, func
from sqlalchemy.orm import sessionmaker, declarative_base, Session
from huggingface_hub import InferenceClient


# ================= 1. é…ç½®æ¨¡å‹ =================
HF_MODEL_NAME = "Qwen/Qwen2.5-72B-Instruct"
HF_TOKEN = os.environ.get("HF_TOKEN", "")
hf_client = InferenceClient(model=HF_MODEL_NAME, token=HF_TOKEN)

# ================= 2. æ•°æ®åº“é…ç½® =================
DATABASE_URL = "sqlite:///./writing_coach.db"
engine = create_engine(DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()


# --- è¡¨å®šä¹‰ ---
class Submission(Base):
    __tablename__ = "submissions"
    id = Column(Integer, primary_key=True, index=True)
    topic_title = Column(String(255), nullable=True)  # è®°å½•é¢˜ç›®(å¦‚æœæ˜¯è¯é¢˜å†™ä½œ)
    user_text = Column(Text)
    evaluation = Column(SA_JSON)
    created_at = Column(DateTime(timezone=True), server_default=func.now())


class Topic(Base):
    __tablename__ = "topics"
    id = Column(Integer, primary_key=True, index=True)
    title = Column(String(255))      # è¯é¢˜æ ‡é¢˜
    description = Column(Text)       # å…·ä½“é—®é¢˜æè¿°
    category = Column(String(50))    # ç±»åˆ« (Technology, Environment...)


# ================= 3. æ•°æ®æ¨¡å‹ =================
class TopicOut(BaseModel):
    id: int
    title: str
    description: str
    category: str


class WritingRequest(BaseModel):
    text: str
    topic: Optional[str] = None  # å…è®¸ä¼ å…¥é¢˜ç›®ï¼Œè¾…åŠ©AIè¯„åˆ†


class WritingResponse(BaseModel):
    status: str
    id: int
    report: Dict[str, Any]


# ================= 4. Prompt é€»è¾‘ =================
def build_examiner_prompt(text: str, topic: str = None) -> str:
    """æ„å»ºé›…æ€å†™ä½œè¯„åˆ†çš„ Prompt"""
    topic_context = ""
    if topic:
        topic_context = f'The user is writing based on this TOPIC:\n"{topic}"\nCheck if the response addresses this topic relevantly.\n'

    return f"""
    You are an expert IELTS examiner and English editor.
    {topic_context}

    Evaluate the following text strictly.
    Input Text:
    \"\"\"{text}\"\"\"

    Task:
    1. Score based on **IELTS Writing Criteria** (0-9 scale):
       - Task Response (Did they answer the topic? If no topic provided, assume open topic)
       - Coherence & Cohesion
       - Lexical Resource
       - Grammatical Range & Accuracy

    2. Score based on **General Quality** (0-9 scale):
       - Idiomatic/Native-like Phrasing
       - Grammar Accuracy
       - Spelling

    3. Provide a **Native-level Rewrite**.

    Output STRICT JSON format:
    {{
      "ielts": {{
        "overall": 6.5,
        "criteria": {{
            "task_response": {{ "score": 6.0, "comment": "..." }},
            "coherence": {{ "score": 6.5, "comment": "..." }},
            "lexical": {{ "score": 7.0, "comment": "..." }},
            "grammar": {{ "score": 6.0, "comment": "..." }}
        }}
      }},
      "general": {{
        "overall": 7.0,
        "criteria": {{
            "native_phrasing": {{ "score": 6.0, "comment": "..." }},
            "grammar_accuracy": {{ "score": 7.5, "comment": "..." }},
            "spelling": {{ "score": 9.0, "comment": "..." }}
        }}
      }},
      "overall_feedback": "Summary...",
      "improved_version": "Rewritten text..."
    }}
    """


def call_llm(prompt: str) -> Optional[Dict]:
    """è°ƒç”¨ LLM è·å–è¯„åˆ†æŠ¥å‘Š"""
    full_prompt = "You are a JSON generator. Output only JSON.\n" + prompt
    try:
        resp = hf_client.chat_completion(
            messages=[{"role": "user", "content": full_prompt}],
            max_tokens=2500, 
            temperature=0.5
        )
        raw = resp.choices[0].message.content.strip()
        if "[" in raw:
            raw = raw[raw.find("["):raw.rfind("]")+1]
        elif "{" in raw:
            raw = raw[raw.find("{"):raw.rfind("}")+1]
        return json.loads(raw)
    except Exception as e:
        print(f"LLM Error: {e}")
        return None


# ================= 5. FastAPI åº”ç”¨ =================
def create_app() -> FastAPI:
    """åˆ›å»º FastAPI åº”ç”¨"""
    app = FastAPI(title="AI Writing Coach")
    app.add_middleware(
        CORSMiddleware, 
        allow_origins=["*"], 
        allow_credentials=True, 
        allow_methods=["*"], 
        allow_headers=["*"]
    )
    
    return app


def get_db():
    """è·å–æ•°æ®åº“ä¼šè¯"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“å’Œè¯é¢˜åº“"""
    Base.metadata.create_all(bind=engine)
    
    db = SessionLocal()
    try:
        if db.query(Topic).count() == 0:
            print("ğŸŒ± æ­£åœ¨åˆå§‹åŒ–è¯é¢˜åº“...")
            topics = [
                {
                    "category": "Education", 
                    "title": "Online Education vs Classroom", 
                    "description": "Some people believe that online education is better than traditional classroom learning. To what extent do you agree or disagree?"
                },
                {
                    "category": "Technology", 
                    "title": "AI in Workplace", 
                    "description": "Artificial Intelligence is replacing many human jobs. Is this a positive or negative development?"
                },
                {
                    "category": "Environment", 
                    "title": "Plastic Waste", 
                    "description": "Plastic pollution is a major problem. What are the causes and what solutions can you suggest?"
                },
                {
                    "category": "Society", 
                    "title": "Work-Life Balance", 
                    "description": "Many people nowadays work longer hours and have less time for leisure. What are the effects of this trend?"
                },
                {
                    "category": "Culture", 
                    "title": "Tourism Impacts", 
                    "description": "International tourism creates tension between people from different cultures. Do you agree or disagree?"
                },
                {
                    "category": "Health", 
                    "title": "Sugar Tax", 
                    "description": "Governments should impose a tax on sugary drinks to improve public health. Discuss the advantages and disadvantages."
                }
            ]
            for t in topics:
                db.add(Topic(**t))
            db.commit()
            print("âœ… è¯é¢˜åº“åˆå§‹åŒ–å®Œæˆ")
    finally:
        db.close()


# ================= 6. API è·¯ç”± =================
def setup_routes(app: FastAPI):
    """è®¾ç½® API è·¯ç”±"""
    
    @app.get("/topics", response_model=List[TopicOut])
    def get_topics(db: Session = Depends(get_db)):
        """è·å–è¯é¢˜åˆ—è¡¨"""
        return db.query(Topic).all()

    @app.post("/evaluate", response_model=WritingResponse)
    def evaluate_text(req: WritingRequest, db: Session = Depends(get_db)):
        """è¯„ä»·å†™ä½œæ–‡æœ¬"""
        if len(req.text.split()) < 3:
            raise HTTPException(status_code=400, detail="Text too short.")

        # æ„å»º Prompt (å¦‚æœé€‰äº†è¯é¢˜ï¼ŒæŠŠè¯é¢˜ä¹Ÿä¼ è¿›å»)
        prompt = build_examiner_prompt(req.text, req.topic)
        report = call_llm(prompt)

        if not report:
            raise HTTPException(status_code=500, detail="AI failed to generate report.")

        sub = Submission(user_text=req.text, topic_title=req.topic, evaluation=report)
        db.add(sub)
        db.commit()
        db.refresh(sub)

        return {"status": "ok", "id": sub.id, "report": report}

    @app.get("/history")
    def get_history(limit: int = 10, db: Session = Depends(get_db)):
        """è·å–å†å²è®°å½•"""
        subs = db.query(Submission).order_by(Submission.id.desc()).limit(limit).all()
        return [
            {
                "id": s.id, 
                "preview": s.user_text[:50] + "...", 
                "topic": s.topic_title,
                "score": s.evaluation.get("ielts", {}).get("overall"),
                "created_at": s.created_at.isoformat() if s.created_at else None
            } 
            for s in subs
        ]


# ================= 7. è¾…åŠ©å‡½æ•° =================
def print_progress(score, label):
    """æ‰“å°è¯„åˆ†æ¡"""
    if score is None:
        score = 0
    score = float(score)
    bar_len = 10
    filled = int((score / 9.0) * bar_len)
    bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
    print(f"   {label.ljust(22)}: {score}/9.0  [{bar}]")


def print_report(data: Dict):
    """æ‰“å°è¯„åˆ†æŠ¥å‘Š"""
    print(f"\n{'='*20} ğŸ“ è¯„åˆ†æŠ¥å‘Š {'='*20}")

    # é›…æ€
    ielts = data.get("ielts", {})
    print(f"\nã€ğŸ“š é›…æ€è¯„åˆ† (Overall: {ielts.get('overall')})ã€‘")
    crit = ielts.get("criteria", {})
    print_progress(crit.get("task_response", {}).get("score"), "Task Response")
    print_progress(crit.get("coherence", {}).get("score"), "Coherence")
    print_progress(crit.get("lexical", {}).get("score"), "Lexical")
    print_progress(crit.get("grammar", {}).get("score"), "Grammar")

    # é€šç”¨
    gen = data.get("general", {})
    print(f"\nã€ğŸŒ é€šç”¨è¯„åˆ† (Overall: {gen.get('overall')})ã€‘")
    crit_g = gen.get("criteria", {})
    print_progress(crit_g.get("native_phrasing", {}).get("score"), "åœ°é“ç¨‹åº¦")
    print_progress(crit_g.get("grammar_accuracy", {}).get("score"), "è¯­æ³•å‡†ç¡®")
    print_progress(crit_g.get("spelling", {}).get("score"), "æ‹¼å†™")

    # åé¦ˆ & æ¶¦è‰²
    print(f"\nã€ğŸ’¬ ç‚¹è¯„ã€‘ {data.get('overall_feedback')}")
    print(f"\nã€âœ¨ æ¶¦è‰²ã€‘ {data.get('improved_version')}")
    print("\n" + "="*60)


if __name__ == "__main__":
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    
    # åˆ›å»ºåº”ç”¨
    app = create_app()
    setup_routes(app)
    
    # å¯åŠ¨æœåŠ¡å™¨
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
