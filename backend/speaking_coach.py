"""
AI å£è¯­ç§æ•™æ¨¡å— - æä¾›è¯­éŸ³è¯†åˆ«å’Œé›…æ€å£è¯­è¯„åˆ†åŠŸèƒ½
æ”¯æŒæµè§ˆå™¨éº¦å…‹é£å½•éŸ³ (éœ€è¦åœ¨ Jupyter Notebook ç¯å¢ƒä¸­è¿è¡Œ)
"""
import os
import json
from typing import Optional, Dict
from huggingface_hub import InferenceClient


# ================= 1. é…ç½®æ¨¡å‹ =================
HF_MODEL_NAME = "Qwen/Qwen2.5-72B-Instruct"
HF_TOKEN = os.environ.get("HF_TOKEN", "")
hf_client = InferenceClient(model=HF_MODEL_NAME, token=HF_TOKEN)


# ================= 2. è¯­éŸ³è¯†åˆ« =================
def load_whisper_model(model_size: str = "base"):
    """
    åŠ è½½ Whisper è¯­éŸ³è¯†åˆ«æ¨¡å‹
    
    Args:
        model_size: æ¨¡å‹å¤§å° (tiny, base, small, medium, large)
    """
    try:
        import whisper
        print(f"â³ æ­£åœ¨åŠ è½½ Whisper {model_size} æ¨¡å‹...")
        model = whisper.load_model(model_size)
        print("âœ… Whisper åŠ è½½å®Œæˆï¼")
        return model
    except ImportError:
        print("âŒ è¯·å…ˆå®‰è£… openai-whisper: pip install git+https://github.com/openai/whisper.git")
        return None


def transcribe_audio(model, audio_file: str) -> str:
    """
    å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡å­—
    
    Args:
        model: Whisper æ¨¡å‹
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    
    Returns:
        è¯†åˆ«çš„æ–‡æœ¬
    """
    if model is None:
        raise ValueError("Whisper model not loaded")
    
    result = model.transcribe(audio_file)
    return result["text"].strip()


# ================= 3. å£è¯­è¯„ä»· Prompt =================
def build_speaking_prompt(text: str) -> str:
    """æ„å»ºé›…æ€å£è¯­è¯„åˆ†çš„ Prompt"""
    return f"""
    You are an expert IELTS Speaking Examiner.
    The user has just spoken the following text (transcribed from audio).

    Transcribed Text:
    \"\"\"{text}\"\"\"

    Task:
    Evaluate this response based on **IELTS Speaking Criteria** (Band 0-9).
    Since you cannot hear the audio, assume pronunciation is clear but judge based on:
    1. **Fluency and Coherence**: Is the answer logical? Is it long enough?
    2. **Lexical Resource**: Did they use idiomatic language?
    3. **Grammatical Range and Accuracy**: Are there errors?

    Output STRICT JSON format:
    {{
      "overall_band": 6.5,
      "feedback": {{
        "fluency": {{ "score": 6.0, "comment": "..." }},
        "vocabulary": {{ "score": 7.0, "comment": "..." }},
        "grammar": {{ "score": 6.5, "comment": "..." }}
      }},
      "native_suggestion": "How a native speaker would say this..."
    }}
    """


def get_ai_feedback(text: str) -> Optional[Dict]:
    """
    è·å– AI å£è¯­è¯„åˆ†åé¦ˆ
    
    Args:
        text: è¯†åˆ«çš„æ–‡æœ¬
    
    Returns:
        è¯„åˆ†æŠ¥å‘Šå­—å…¸
    """
    prompt = build_speaking_prompt(text)
    full_prompt = "You are a JSON generator. Output only JSON.\n" + prompt
    
    try:
        resp = hf_client.chat_completion(
            messages=[{"role": "user", "content": full_prompt}],
            max_tokens=1500, 
            temperature=0.7
        )
        raw = resp.choices[0].message.content.strip()
        
        if "[" in raw:
            raw = raw[raw.find("["):raw.rfind("]")+1]
        elif "{" in raw:
            raw = raw[raw.find("{"):raw.rfind("}")+1]
        
        return json.loads(raw)
    except Exception as e:
        print(f"Error: {e}")
        return None


# ================= 4. æŠ¥å‘Šæ‰“å° =================
def print_speaking_report(report: Dict):
    """æ‰“å°å£è¯­è¯„åˆ†æŠ¥å‘Š"""
    if not report:
        print("âŒ æ— æ³•ç”Ÿæˆè¯„åˆ†æŠ¥å‘Š")
        return
    
    print(f"\n{'='*20} ğŸ“Š å£è¯­æˆç»©å• {'='*20}")
    print(f"ğŸ† é¢„ä¼°é›…æ€åˆ†æ•°: {report.get('overall_band')}")

    fb = report.get('feedback', {})
    print(f"\n1. æµåˆ©åº¦ (Fluency): {fb.get('fluency', {}).get('score')} - {fb.get('fluency', {}).get('comment')}")
    print(f"2. è¯æ±‡ (Vocab):   {fb.get('vocabulary', {}).get('score')} - {fb.get('vocabulary', {}).get('comment')}")
    print(f"3. è¯­æ³• (Grammar): {fb.get('grammar', {}).get('score')} - {fb.get('grammar', {}).get('comment')}")

    print(f"\nâœ¨ åœ°é“è¡¨è¾¾å»ºè®®: \n{report.get('native_suggestion')}")
    print("="*50)


# ================= 5. ä¸»æµç¨‹ =================
def evaluate_speaking(audio_file: str, whisper_model=None) -> Optional[Dict]:
    """
    å®Œæ•´çš„å£è¯­è¯„ä»·æµç¨‹
    
    Args:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        whisper_model: Whisper æ¨¡å‹ (å¦‚æœæœªæä¾›åˆ™ä¼šè‡ªåŠ¨åŠ è½½)
    
    Returns:
        è¯„åˆ†æŠ¥å‘Šå­—å…¸
    """
    # åŠ è½½æ¨¡å‹
    if whisper_model is None:
        whisper_model = load_whisper_model()
    
    if whisper_model is None:
        return None
    
    # è¯†åˆ«è¯­éŸ³
    print("\nğŸ§ æ­£åœ¨è¯†åˆ«è¯­éŸ³ (Transcribing)...")
    user_text = transcribe_audio(whisper_model, audio_file)
    print(f"\nğŸ“ è¯†åˆ«ç»“æœ: \"{user_text}\"")
    
    if len(user_text) < 5:
        print("âš ï¸ æ²¡å¬æ¸…ï¼Œæˆ–è€…è¯´å¾—å¤ªçŸ­äº†ï¼Œè¯·é‡è¯•ã€‚")
        return None
    
    # AI è¯„åˆ†
    print("ğŸ¤– è€ƒå®˜æ­£åœ¨è¯„åˆ† (Evaluating)...")
    report = get_ai_feedback(user_text)
    
    return report


# ================= 6. æµè§ˆå™¨éº¦å…‹é£å½•éŸ³æ”¯æŒ =================
AUDIO_HTML = """
<script>
var my_div = document.createElement('div');
var my_p = document.createElement('p');
var my_btn = document.createElement('button');
var my_status = document.createElement('p');

my_p.innerHTML = '<h3>ğŸ™ï¸ æµè§ˆå™¨éº¦å…‹é£å½•éŸ³</h3>';
my_btn.style.cssText = 'padding: 15px 30px; font-size: 16px; background: #4CAF50; color: white; border: none; border-radius: 5px; cursor: pointer;';
my_status.style.cssText = 'color: #666; margin-top: 10px;';

my_div.appendChild(my_p);
my_div.appendChild(my_btn);
my_div.appendChild(my_status);
document.body.appendChild(my_div);

var base64data = 0;
var reader;
var recorder, gumStream;
var recordButton = my_btn;
var statusText = my_status;

var handleSuccess = function(stream) {
  gumStream = stream;
  var options = {
    mimeType : 'audio/webm;codecs=opus'
  };
  recorder = new MediaRecorder(stream, options);
  recorder.ondataavailable = function(e) {
    var url = URL.createObjectURL(e.data);
    var preview = document.createElement('audio');
    preview.controls = true;
    preview.src = url;
    preview.style.cssText = 'margin-top: 10px; width: 100%;';
    document.body.appendChild(preview);

    reader = new FileReader();
    reader.readAsDataURL(e.data);
    reader.onloadend = function() {
      base64data = reader.result;
    }
  };
  recorder.start();
  };

recordButton.innerText = "ğŸ™ï¸ ç‚¹å‡»å¼€å§‹å½•éŸ³";
statusText.innerText = "å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»æŒ‰é’®å¼€å§‹å½•éŸ³...";

navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(err) {
  statusText.innerText = "âŒ æ— æ³•è®¿é—®éº¦å…‹é£: " + err.message;
  recordButton.disabled = true;
});

function toggleRecording() {
  if (recorder && recorder.state == "recording") {
      recorder.stop();
      gumStream.getAudioTracks()[0].stop();
      recordButton.innerText = "â³ å¤„ç†ä¸­...";
      recordButton.style.background = "#FF9800";
      statusText.innerText = "æ­£åœ¨å¤„ç†å½•éŸ³ï¼Œè¯·ç¨å€™...";
      return "stop";
  }
}

function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

var data = new Promise(resolve=>{
  recordButton.onclick = ()=>{
    if (recorder.state == "recording") {
        toggleRecording()
        sleep(2000).then(() => {
            resolve(base64data.toString())
        });
    } else {
        recordButton.innerText = "â¹ï¸ ç‚¹å‡»åœæ­¢å½•éŸ³";
        recordButton.style.background = "#f44336";
        statusText.innerText = "ğŸ”´ æ­£åœ¨å½•éŸ³ä¸­...";
    }
  }
});
</script>
"""


def get_audio_from_browser(output_file: str = "user_audio.wav") -> str:
    """
    é€šè¿‡æµè§ˆå™¨éº¦å…‹é£å½•åˆ¶éŸ³é¢‘
    
    Args:
        output_file: è¾“å‡ºæ–‡ä»¶å
    
    Returns:
        éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    try:
        from IPython.display import HTML, display
        from base64 import b64decode
    except ImportError:
        raise ImportError("æ­¤åŠŸèƒ½éœ€è¦åœ¨ Jupyter Notebook ç¯å¢ƒä¸­è¿è¡Œ")
    
    # å°è¯•å¯¼å…¥ eval_js (Colab) æˆ– ä½¿ç”¨é€šç”¨æ–¹æ³•
    try:
        from google.colab.output import eval_js
    except ImportError:
        try:
            # å°è¯•ä½¿ç”¨ ipywidgets çš„æ–¹å¼
            from IPython.display import Javascript
            eval_js = lambda x: Javascript(x)
        except:
            raise ImportError("æ— æ³•æ‰¾åˆ° JavaScript æ‰§è¡Œç¯å¢ƒï¼Œè¯·åœ¨ Jupyter Notebook æˆ– Google Colab ä¸­è¿è¡Œ")
    
    display(HTML(AUDIO_HTML))
    data = eval_js("data")
    binary = b64decode(data.split(',')[1])

    # è½¬æ¢éŸ³é¢‘æ ¼å¼
    try:
        import ffmpeg
        process = (ffmpeg
            .input('pipe:0')
            .output('pipe:1', format='wav')
            .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)
        )
        output, err = process.communicate(input=binary)

        riff_chunk_size = len(output) - 8
        q = riff_chunk_size
        b = []
        for i in range(4):
            q, r = divmod(q, 256)
            b.append(r)

        riff = output[:4] + bytes(b) + output[8:]

        with open(output_file, 'wb') as f:
            f.write(riff)
    except ImportError:
        # å¦‚æœæ²¡æœ‰ ffmpegï¼Œç›´æ¥ä¿å­˜ webm æ ¼å¼
        print("âš ï¸ æœªå®‰è£… ffmpegï¼Œå°†ä¿å­˜ä¸º webm æ ¼å¼")
        output_file = output_file.replace('.wav', '.webm')
        with open(output_file, 'wb') as f:
            f.write(binary)
    
    return output_file


def start_speaking_coach_browser():
    """é€šè¿‡æµè§ˆå™¨éº¦å…‹é£å¯åŠ¨å£è¯­ç§æ•™"""
    print(f"\n{'='*15} ğŸ—£ï¸ AI å£è¯­æ¨¡æ‹Ÿè€ƒå®˜ (Speaking Coach) {'='*15}")
    print("å‡†å¤‡é€šè¿‡æµè§ˆå™¨éº¦å…‹é£å½•éŸ³...\n")

    # åŠ è½½æ¨¡å‹
    stt_model = load_whisper_model("base")
    if stt_model is None:
        return

    try:
        # å½•éŸ³
        print("è¯·åœ¨ä¸‹æ–¹ç‚¹å‡»æŒ‰é’®å¼€å§‹å½•éŸ³ï¼Œè¯´å®Œåå†æ¬¡ç‚¹å‡»åœæ­¢ã€‚")
        audio_file = get_audio_from_browser()
        
        # è¯„ä»·
        report = evaluate_speaking(audio_file, stt_model)
        
        # æ‰“å°æŠ¥å‘Š
        if report:
            print_speaking_report(report)
    except Exception as e:
        print(f"âŒ å½•éŸ³è¢«å–æ¶ˆæˆ–å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·é‡æ–°è¿è¡Œæ­¤å‡½æ•°ã€‚")


if __name__ == "__main__":
    print("å£è¯­ç§æ•™æ¨¡å—åŠ è½½å®Œæˆ")
    print("ä½¿ç”¨æ–¹æ³•:")
    print("1. åœ¨ Jupyter Notebook ä¸­: è°ƒç”¨ start_speaking_coach_browser()")
    print("2. ä½¿ç”¨æœ¬åœ°éŸ³é¢‘æ–‡ä»¶: è°ƒç”¨ evaluate_speaking('audio.wav')")
